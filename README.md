# Skin Lesion Classification Using Machine Learning & Deep Learning**

## ğŸ§  **Overview**

Este repositÃ³rio contÃ©m o projeto desenvolvido para o artigo no formato IEEE, cujo objetivo Ã© **classificar lesÃµes de pele em trÃªs categorias clÃ­nicas** â€” **Benigno**, **Suspeito** e **Maligno** â€” usando tanto **modelos clÃ¡ssicos de Machine Learning** quanto **redes neurais convolucionais (CNN)** com **Transfer Learning**.

O projeto utiliza o dataset **HAM10000** (Skin Cancer MNIST) e inclui:

* ExtraÃ§Ã£o de features tradicionais (HOG, LBP, histogramas)
* Treino e avaliaÃ§Ã£o de modelos:

  * **SVM**
  * **Random Forest**
  * **MLP**
* PreparaÃ§Ã£o de dados para CNN (folder structure + augmentation)
* Transfer Learning com **ResNet50**
* Fine-tuning do modelo
* AvaliaÃ§Ã£o completa (mÃ©tricas + matriz de confusÃ£o)

Este repositÃ³rio tambÃ©m contÃ©m o notebook completo utilizado para gerar todos os experimentos.

---

## ğŸ“Š **Classes trabalhadas**

As 7 classes originais do HAM10000 foram remapeadas para 3 grupos:

| Original        | Novo Grupo   |
| --------------- | ------------ |
| nv, df, vasc    | **Benigno**  |
| bkl             | **Suspeito** |
| mel, bcc, akiec | **Maligno**  |

Esse agrupamento facilita a tarefa clÃ­nica e melhora a robustez do modelo.

---


## ğŸ“¦ **Dataset**

O dataset principal Ã©:

### **HAM10000 â€” Skin Cancer MNIST**

DisponÃ­vel publicamente no Kaggle:
[https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000](https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000)

O download do dataset no notebook Ã© feito automaticamente via:

```python
import kagglehub
path = kagglehub.dataset_download("kmader/skin-cancer-mnist-ham10000")
```

---

## ğŸ§© **Requisitos**

### Se rodar *localmente*:

Instale:

```
pip install numpy pandas matplotlib scikit-learn scikit-image tensorflow kagglehub seaborn tqdm
```

Ou crie um ambiente:

```
python3 -m venv env
source env/bin/activate
pip install -r requirements.txt
```

### Se rodar no **Google Colab**:

Nenhuma instalaÃ§Ã£o extra Ã© necessÃ¡ria alÃ©m das cÃ©lulas do notebook â€” tudo jÃ¡ estÃ¡ automatizado.

---

## ğŸ—ï¸ **Etapas do Notebook**

### **1. PreparaÃ§Ã£o e download do dataset**

* Download via `kagglehub`
* Carregamento dos metadados
* Remapeamento para 3 classes

### **2. Modelos clÃ¡ssicos (ML tradicional)**

* ExtraÃ§Ã£o de features: HOG, LBP, histogramas HSV
* Treino:

  * SVM
  * Random Forest
  * MLP
* AvaliaÃ§Ã£o com mÃ©tricas (precision/recall/F1)

### **3. CNN (Deep Learning)**

* CriaÃ§Ã£o das pastas (train/valid/test)
* Data augmentation
* Transfer learning com ResNet50
* Fine-tuning
* Class weights para balanceamento
* AvaliaÃ§Ã£o completa

### **4. Resultados**

* RelatÃ³rios completos
* Matriz de confusÃ£o
* ComparaÃ§Ã£o entre modelos
* DiscussÃ£o sobre viÃ©s, erros e limitaÃ§Ãµes

---

## ğŸ“ **Artigo IEEE**

O artigo completo estÃ¡ disponÃ­vel no arquivo:

```
IEEE_Trio_Nomes.pdf
```
---

## ğŸ‘¨â€ğŸ’» **Autor**

- Davi Leahy

---

## ğŸ“œ **LicenÃ§a**

MIT License

---